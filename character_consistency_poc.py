#!/usr/bin/env python3
"""
PoC for Character Consistency in Multi-Agent Video Generation Systems

This script demonstrates how to maintain character consistency across multiple agents
processing different scenes of a story using shared memory and coordination.
"""

import asyncio
import json
import os
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict
from datetime import datetime

from transformers import pipeline


@dataclass
class Character:
    """Represents a character with consistent attributes"""
    name: str
    age: Optional[int] = None
    appearance: Optional[str] = None
    personality: Optional[str] = None
    role: Optional[str] = None
    relationships: Dict[str, str] = None

    def __post_init__(self):
        if self.relationships is None:
            self.relationships = {}

    def to_dict(self) -> Dict[str, Any]:
        return {k: v for k, v in asdict(self).items() if v is not None}


@dataclass
class Scene:
    """Represents a scene in the video storyboard"""
    scene_id: int
    description: str
    characters_present: List[str]
    location: str
    time_of_day: Optional[str] = None
    mood: Optional[str] = None
    key_actions: List[str] = None

    def __post_init__(self):
        if self.key_actions is None:
            self.key_actions = []


class SharedMemory:
    """Simulated shared memory for character consistency"""

    def __init__(self):
        self.characters: Dict[str, Character] = {}
        self.scenes: List[Scene] = []
        self.global_context: Dict[str, Any] = {}

    def add_character(self, character: Character):
        """Add or update character in shared memory"""
        self.characters[character.name] = character

    def get_character(self, name: str) -> Optional[Character]:
        """Retrieve character from shared memory"""
        return self.characters.get(name)

    def update_character(self, name: str, **updates):
        """Update character attributes"""
        if name in self.characters:
            char = self.characters[name]
            for key, value in updates.items():
                if hasattr(char, key):
                    setattr(char, key, value)

    def add_scene(self, scene: Scene):
        """Add scene to shared memory"""
        self.scenes.append(scene)

    def get_all_characters(self) -> Dict[str, Character]:
        """Get all characters"""
        return self.characters.copy()

    def get_recent_scenes(self, limit: int = 3) -> List[Scene]:
        """Get recent scenes for context"""
        return self.scenes[-limit:] if self.scenes else []


class StoryProcessingAgent:
    """Base agent for processing story elements"""

    def __init__(self, name: str, generator, shared_memory: SharedMemory):
        self.name = name
        self.generator = generator
        self.shared_memory = shared_memory
        self.memory = []  # Simple list for conversation history

    async def process(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """Process input data and return results"""
        raise NotImplementedError


class CharacterExtractionAgent(StoryProcessingAgent):
    """Agent responsible for extracting and maintaining character information"""

    def __init__(self, llm: ChatOpenAI, shared_memory: SharedMemory):
        super().__init__("CharacterExtractor", llm, shared_memory)

        self.prompt = PromptTemplate(
            input_variables=["story_text", "existing_characters"],
            template="""
            Ø´Ù…Ø§ ÛŒÚ© Ù…ØªØ®ØµØµ ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ Ø¯Ø§Ø³ØªØ§Ù† Ù‡Ø³ØªÛŒØ¯. Ø§Ø² Ù…ØªÙ† Ø¯Ø§Ø³ØªØ§Ù† Ø²ÛŒØ±ØŒ Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ Ø±Ø§ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ø±Ø¯Ù‡ Ùˆ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¢Ù†Ù‡Ø§ Ø±Ø§ ØªØ­Ù„ÛŒÙ„ Ú©Ù†ÛŒØ¯.

            Ø¯Ø§Ø³ØªØ§Ù†:
            {story_text}

            Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ ØªØ§Ú©Ù†ÙˆÙ†:
            {existing_characters}

            Ù„Ø·ÙØ§ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ú©Ø§Ø±Ø§Ú©ØªØ± Ø¬Ø¯ÛŒØ¯ ÛŒØ§ Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ú©Ø§Ø±Ø§Ú©ØªØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø²ÛŒØ± Ø±Ø§ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù†ÛŒØ¯:
            - Ù†Ø§Ù…
            - Ø³Ù† (Ø§Ú¯Ø± Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡)
            - Ø¸Ø§Ù‡Ø± (ØªÙˆØ¶ÛŒØ­ ÙÛŒØ²ÛŒÚ©ÛŒ)
            - Ø´Ø®ØµÛŒØª (ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø±ÙØªØ§Ø±ÛŒ)
            - Ù†Ù‚Ø´ Ø¯Ø± Ø¯Ø§Ø³ØªØ§Ù†
            - Ø±ÙˆØ§Ø¨Ø· Ø¨Ø§ Ø¯ÛŒÚ¯Ø± Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§

            Ø®Ø±ÙˆØ¬ÛŒ Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª JSON Ø¨Ø¯Ù‡ÛŒØ¯:
            {{
                "characters": [
                    {{
                        "name": "Ù†Ø§Ù… Ú©Ø§Ø±Ø§Ú©ØªØ±",
                        "age": Ø¹Ø¯Ø¯ ÛŒØ§ null,
                        "appearance": "ØªÙˆØ¶ÛŒØ­ Ø¸Ø§Ù‡Ø±",
                        "personality": "ØªÙˆØ¶ÛŒØ­ Ø´Ø®ØµÛŒØª",
                        "role": "Ù†Ù‚Ø´ Ø¯Ø± Ø¯Ø§Ø³ØªØ§Ù†",
                        "relationships": {{"Ù†Ø§Ù…_Ø¯ÛŒÚ¯Ø±ÛŒ": "Ù†ÙˆØ¹_Ø±Ø§Ø¨Ø·Ù‡"}}
                    }}
                ]
            }}
            """
        )

    async def process(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        existing_chars = self.shared_memory.get_all_characters()
        existing_chars_json = json.dumps(
            [char.to_dict() for char in existing_chars.values()],
            ensure_ascii=False,
            indent=2
        )

        # Create prompt
        prompt_text = self.prompt.format(
            story_text=input_data["story_text"],
            existing_characters=existing_chars_json
        )

        # Generate response using local model
        outputs = self.generator(prompt_text, max_new_tokens=256, do_sample=True, temperature=0.7)
        result = outputs[0]['generated_text']

        # Extract JSON from response (simple approach)
        try:
            # Try to find JSON in the response
            start_idx = result.find('{')
            end_idx = result.rfind('}') + 1
            if start_idx != -1 and end_idx > start_idx:
                json_str = result[start_idx:end_idx]
                parsed_result = json.loads(json_str)

                # Update shared memory with new characters
                for char_data in parsed_result.get("characters", []):
                    char = Character(**char_data)
                    self.shared_memory.add_character(char)

                return {"characters_extracted": len(parsed_result.get("characters", []))}
            else:
                return {"error": "No JSON found in response", "raw_response": result[:500]}
        except json.JSONDecodeError:
            return {"error": "Failed to parse character extraction result", "raw_response": result[:500]}


class ScenePlanningAgent(StoryProcessingAgent):
    """Agent responsible for breaking story into consistent scenes"""

    def __init__(self, llm: ChatOpenAI, shared_memory: SharedMemory):
        super().__init__("ScenePlanner", llm, shared_memory)

        self.prompt = PromptTemplate(
            input_variables=["story_text", "characters_info", "previous_scenes"],
            template="""
            Ø´Ù…Ø§ ÛŒÚ© Ú©Ø§Ø±Ú¯Ø±Ø¯Ø§Ù† ÙÛŒÙ„Ù… Ù‡Ø³ØªÛŒØ¯ Ú©Ù‡ Ø¯Ø§Ø³ØªØ§Ù† Ø±Ø§ Ø¨Ù‡ ØµØ­Ù†Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆÛŒØ¯ÛŒÙˆ ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒâ€ŒÚ©Ù†ÛŒØ¯.
            Ø¯Ø§Ø³ØªØ§Ù† Ø±Ø§ Ø¨Ù‡ ØµØ­Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ù†Ø·Ù‚ÛŒ ØªÙ‚Ø³ÛŒÙ… Ú©Ù†ÛŒØ¯ Ùˆ Ø§Ø² consistency Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø­Ø§ØµÙ„ Ú©Ù†ÛŒØ¯.

            Ø¯Ø§Ø³ØªØ§Ù†:
            {story_text}

            Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§:
            {characters_info}

            ØµØ­Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ:
            {previous_scenes}

            Ø¨Ø±Ø§ÛŒ Ù‡Ø± ØµØ­Ù†Ù‡ØŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø²ÛŒØ± Ø±Ø§ Ù…Ø´Ø®Øµ Ú©Ù†ÛŒØ¯:
            - Ø´Ù…Ø§Ø±Ù‡ ØµØ­Ù†Ù‡
            - ØªÙˆØµÛŒÙ ØµØ­Ù†Ù‡
            - Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ Ø­Ø§Ø¶Ø±
            - Ù…ÙˆÙ‚Ø¹ÛŒØª Ù…Ú©Ø§Ù†ÛŒ
            - Ø²Ù…Ø§Ù† Ø±ÙˆØ²
            - Ø­Ø§Ù„ Ùˆ Ù‡ÙˆØ§
            - Ø§Ù‚Ø¯Ø§Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ

            Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø­Ø§ØµÙ„ Ú©Ù†ÛŒØ¯ Ú©Ù‡ Ø¸Ø§Ù‡Ø± Ùˆ Ø±ÙØªØ§Ø± Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ Ø¨Ø§ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…ÙˆØ¬ÙˆØ¯ consistency Ø¯Ø§Ø±Ø¯.

            Ø®Ø±ÙˆØ¬ÛŒ Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª JSON Ø¨Ø¯Ù‡ÛŒØ¯:
            {{
                "scenes": [
                    {{
                        "scene_id": Ø¹Ø¯Ø¯,
                        "description": "ØªÙˆØ¶ÛŒØ­ ØµØ­Ù†Ù‡",
                        "characters_present": ["Ù†Ø§Ù…1", "Ù†Ø§Ù…2"],
                        "location": "Ù…ÙˆÙ‚Ø¹ÛŒØª",
                        "time_of_day": "ØµØ¨Ø­/Ø¹ØµØ±/Ø´Ø¨",
                        "mood": "Ø­Ø§Ù„ Ùˆ Ù‡ÙˆØ§",
                        "key_actions": ["Ø§Ù‚Ø¯Ø§Ù…1", "Ø§Ù‚Ø¯Ø§Ù…2"]
                    }}
                ]
            }}
            """
        )

    async def process(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        characters = self.shared_memory.get_all_characters()
        characters_json = json.dumps(
            [char.to_dict() for char in characters.values()],
            ensure_ascii=False,
            indent=2
        )

        recent_scenes = self.shared_memory.get_recent_scenes()
        scenes_json = json.dumps(
            [asdict(scene) for scene in recent_scenes],
            ensure_ascii=False,
            indent=2
        )

        chain = LLMChain(llm=self.llm, prompt=self.prompt)
        result = await chain.arun(
            story_text=input_data["story_text"],
            characters_info=characters_json,
            previous_scenes=scenes_json
        )

        try:
            parsed_result = json.loads(result)
            # Add scenes to shared memory
            for scene_data in parsed_result.get("scenes", []):
                scene = Scene(**scene_data)
                self.shared_memory.add_scene(scene)

            return {"scenes_planned": len(parsed_result.get("scenes", []))}
        except json.JSONDecodeError:
            return {"error": "Failed to parse scene planning result"}


class ConsistencyValidationAgent(StoryProcessingAgent):
    """Agent responsible for validating character consistency across scenes"""

    def __init__(self, llm: ChatOpenAI, shared_memory: SharedMemory):
        super().__init__("ConsistencyValidator", llm, shared_memory)

        self.prompt = PromptTemplate(
            input_variables=["scenes", "characters_info"],
            template="""
            Ø´Ù…Ø§ ÛŒÚ© validator consistency Ù‡Ø³ØªÛŒØ¯. ØµØ­Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ± Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯ Ùˆ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø­Ø§ØµÙ„ Ú©Ù†ÛŒØ¯ Ú©Ù‡ Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ Ø¯Ø± Ù‡Ù…Ù‡ ØµØ­Ù†Ù‡â€ŒÙ‡Ø§ consistent Ù‡Ø³ØªÙ†Ø¯.

            Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§:
            {characters_info}

            ØµØ­Ù†Ù‡â€ŒÙ‡Ø§:
            {scenes}

            Ø¨Ø±Ø§ÛŒ Ù‡Ø± inconsistencyØŒ Ù…Ø´Ú©Ù„ Ø±Ø§ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú©Ø±Ø¯Ù‡ Ùˆ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø§ØµÙ„Ø§Ø­ Ø¨Ø¯Ù‡ÛŒØ¯.

            Ø®Ø±ÙˆØ¬ÛŒ Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª JSON Ø¨Ø¯Ù‡ÛŒØ¯:
            {{
                "validation_results": [
                    {{
                        "scene_id": Ø¹Ø¯Ø¯,
                        "is_consistent": true/false,
                        "issues": ["Ù…Ø´Ú©Ù„1", "Ù…Ø´Ú©Ù„2"],
                        "suggestions": ["Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯1", "Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯2"]
                    }}
                ],
                "overall_consistency": "Ù†Ø³Ø¨Øª consistency Ú©Ù„ÛŒ (Ù…Ø«Ø§Ù„: 85%)"
            }}
            """
        )

    async def process(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        characters = self.shared_memory.get_all_characters()
        characters_json = json.dumps(
            [char.to_dict() for char in characters.values()],
            ensure_ascii=False,
            indent=2
        )

        scenes = self.shared_memory.scenes
        scenes_json = json.dumps(
            [asdict(scene) for scene in scenes],
            ensure_ascii=False,
            indent=2
        )

        chain = LLMChain(llm=self.llm, prompt=self.prompt)
        result = await chain.arun(
            characters_info=characters_json,
            scenes=scenes_json
        )

        try:
            return json.loads(result)
        except json.JSONDecodeError:
            return {"error": "Failed to parse validation result"}


class MultiAgentOrchestrator:
    """Orchestrates the multi-agent system for video generation"""

    def __init__(self):
        # Use local GPT-2 model (no API key required)
        print("ğŸ”„ Loading local GPT-2 model... (this may take a moment)")
        self.generator = pipeline(
            "text-generation",
            model="gpt2",
            max_new_tokens=256,  # Limit output length
            temperature=0.7,
            do_sample=True,
            pad_token_id=50256,
            repetition_penalty=1.1  # Reduce repetition
        )
        self.shared_memory = SharedMemory()
        self.agents = {}

    def initialize_agents(self):
        """Initialize all agents"""
        self.agents["character_extractor"] = CharacterExtractionAgent(
            self.generator, self.shared_memory
        )
        self.agents["scene_planner"] = ScenePlanningAgent(
            self.generator, self.shared_memory
        )
        self.agents["consistency_validator"] = ConsistencyValidationAgent(
            self.generator, self.shared_memory
        )

    async def process_story(self, story_text: str) -> Dict[str, Any]:
        """Process a story through the multi-agent pipeline"""

        print("ğŸš€ Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø³ØªØ§Ù†...")
        print(f"ğŸ“– Ø·ÙˆÙ„ Ø¯Ø§Ø³ØªØ§Ù†: {len(story_text)} Ú©Ø§Ø±Ø§Ú©ØªØ±")

        # Phase 1: Character Extraction
        print("\nğŸ“ Ù…Ø±Ø­Ù„Ù‡ 1: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§...")
        char_result = await self.agents["character_extractor"].process({
            "story_text": story_text
        })
        print(f"âœ… {char_result.get('characters_extracted', 0)} Ú©Ø§Ø±Ø§Ú©ØªØ± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯")

        # Phase 2: Scene Planning
        print("\nğŸ¬ Ù…Ø±Ø­Ù„Ù‡ 2: Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØ±ÛŒØ²ÛŒ ØµØ­Ù†Ù‡â€ŒÙ‡Ø§...")
        scene_result = await self.agents["scene_planner"].process({
            "story_text": story_text
        })
        print(f"âœ… {scene_result.get('scenes_planned', 0)} ØµØ­Ù†Ù‡ Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØ±ÛŒØ²ÛŒ Ø´Ø¯")

        # Phase 3: Consistency Validation
        print("\nğŸ” Ù…Ø±Ø­Ù„Ù‡ 3: Ø¨Ø±Ø±Ø³ÛŒ consistency...")
        validation_result = await self.agents["consistency_validator"].process({})
        consistency_score = validation_result.get("overall_consistency", "Ù†Ø§Ù…Ø´Ø®Øµ")
        print(f"âœ… Ø§Ù…ØªÛŒØ§Ø² consistency: {consistency_score}")

        # Prepare final output
        output = {
            "metadata": {
                "processing_timestamp": datetime.now().isoformat(),
                "story_length": len(story_text),
                "agents_used": list(self.agents.keys())
            },
            "characters": [char.to_dict() for char in self.shared_memory.characters.values()],
            "scenes": [asdict(scene) for scene in self.shared_memory.scenes],
            "validation": validation_result,
            "summary": {
                "total_characters": len(self.shared_memory.characters),
                "total_scenes": len(self.shared_memory.scenes),
                "consistency_score": consistency_score
            }
        }

        print("\nğŸ‰ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø§Ù…Ù„ Ø´Ø¯!")
        return output


async def main():
    """Main function to demonstrate the PoC"""

    print("ğŸš€ Ø´Ø±ÙˆØ¹ Ø³ÛŒØ³ØªÙ… Multi-Agent Ø¨Ø§ Ù…Ø¯Ù„ Ù…Ø­Ù„ÛŒ GPT-2")
    print("ğŸ“ Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ API key Ù†ÛŒØ³Øª - Ø§Ø² Ù…Ø¯Ù„ Ù…Ø­Ù„ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯")

    # Initialize orchestrator (no API key needed)
    orchestrator = MultiAgentOrchestrator()
    orchestrator.initialize_agents()

    # Sample story (Persian)
    sample_story = """
    Ø¯Ø± Ø´Ù‡Ø±ÛŒ Ø¨Ø²Ø±Ú¯ØŒ Ù¾Ø³Ø±Ú©ÛŒ Ø¨Ù‡ Ù†Ø§Ù… Ø¹Ù„ÛŒ Ø²Ù†Ø¯Ú¯ÛŒ Ù…ÛŒâ€ŒÚ©Ø±Ø¯. Ø¹Ù„ÛŒ Û±Û² Ø³Ø§Ù„Ù‡ Ø¨ÙˆØ¯ Ùˆ Ù…ÙˆÙ‡Ø§ÛŒ Ø³ÛŒØ§Ù‡ Ùˆ Ú†Ø´Ù…Ø§Ù†ÛŒ Ø¨Ø§Ù‡ÙˆØ´ Ø¯Ø§Ø´Øª.
    Ø§Ùˆ Ù‡Ù…ÛŒØ´Ù‡ Ù…Ø§Ø¬Ø±Ø§Ø¬Ùˆ Ùˆ Ú©Ù†Ø¬Ú©Ø§Ùˆ Ø¨ÙˆØ¯. ÛŒÚ© Ø±ÙˆØ² Ø¹Ù„ÛŒ ØªØµÙ…ÛŒÙ… Ú¯Ø±ÙØª Ø¨Ù‡å…¬å›­ Ø¨Ø±ÙˆØ¯ Ùˆ Ù…Ø§Ø¬Ø±Ø§Ø¬ÙˆÛŒÛŒ Ú©Ù†Ø¯.

    Ø¯Ø± Ù¾Ø§Ø±Ú©ØŒ Ø¹Ù„ÛŒ Ø¨Ø§ Ø¯Ø®ØªØ±ÛŒ Ø¨Ù‡ Ù†Ø§Ù… Ø³Ø§Ø±Ø§ Ø¢Ø´Ù†Ø§ Ø´Ø¯. Ø³Ø§Ø±Ø§ Û±Û± Ø³Ø§Ù„Ù‡ Ø¨ÙˆØ¯ Ùˆ Ù…ÙˆÙ‡Ø§ÛŒ Ø¨Ù„ÙˆÙ†Ø¯ Ùˆ Ú†Ø´Ù…Ø§Ù†ÛŒ Ø¢Ø¨ÛŒ Ø¯Ø§Ø´Øª.
    Ø§Ùˆ Ø¢Ø±Ø§Ù… Ùˆ Ú©ØªØ§Ø¨Ø®ÙˆØ§Ù† Ø¨ÙˆØ¯. Ø¢Ù†Ù‡Ø§ Ø¨Ø§ Ù‡Ù… Ø´Ø±ÙˆØ¹ Ø¨Ù‡ Ø¨Ø§Ø²ÛŒ Ú©Ø±Ø¯Ù†Ø¯ Ùˆ Ø¯ÙˆØ³ØªÛŒ Ù†Ø²Ø¯ÛŒÚ©ÛŒ Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù†Ø¯.

    Ù†Ø§Ú¯Ù‡Ø§Ù† Ù‡ÙˆØ§ Ø§Ø¨Ø±ÛŒ Ø´Ø¯ Ùˆ Ø¨Ø§Ø±Ø§Ù† Ø´Ø±ÙˆØ¹ Ø¨Ù‡ Ø¨Ø§Ø±ÛŒØ¯Ù† Ú©Ø±Ø¯. Ø¹Ù„ÛŒ Ùˆ Ø³Ø§Ø±Ø§ Ø²ÛŒØ± Ø¯Ø±Ø®ØªÛŒ Ù¾Ù†Ø§Ù‡ Ú¯Ø±ÙØªÙ†Ø¯.
    Ø¹Ù„ÛŒ Ø¨Ø§ ÙˆØ¬ÙˆØ¯ ØªØ±Ø³ Ø§Ø² Ø±Ø¹Ø¯ Ùˆ Ø¨Ø±Ù‚ØŒ Ø³Ø¹ÛŒ Ú©Ø±Ø¯ Ø³Ø§Ø±Ø§ Ø±Ø§ Ø¢Ø±Ø§Ù… Ú©Ù†Ø¯. Ø³Ø§Ø±Ø§ Ù‡Ù… Ø¨Ø§ Ø®ÙˆØ§Ù†Ø¯Ù† Ø¯Ø§Ø³ØªØ§Ù†ØŒ Ø¬Ùˆ Ø±Ø§ Ø¨Ù‡ØªØ± Ú©Ø±Ø¯.

    Ø¨Ø¹Ø¯ Ø§Ø² Ú¯Ø°Ø´Øª Ø¨Ø§Ø±Ø§Ù†ØŒ Ø¢Ù†Ù‡Ø§ Ø¨Ù‡ Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒØ´Ø§Ù† Ø¨Ø±Ú¯Ø´ØªÙ†Ø¯ Ùˆ Ù‚ÙˆÙ„ Ø¯Ø§Ø¯Ù†Ø¯ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ù‡Ù…Ø¯ÛŒÚ¯Ø± Ø±Ø§ Ø¨Ø¨ÛŒÙ†Ù†Ø¯.
    """

    print("ğŸ“š Ø¯Ø§Ø³ØªØ§Ù† Ù†Ù…ÙˆÙ†Ù‡:")
    print(sample_story)
    print("\n" + "="*50)

    # Process the story
    result = await orchestrator.process_story(sample_story)

    # Save results
    output_file = "storyboard_output.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ’¾ Ù†ØªÛŒØ¬Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„ {output_file} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")

    # Display summary
    print("\nğŸ“Š Ø®Ù„Ø§ØµÙ‡ Ù†ØªØ§ÛŒØ¬:")
    print(f"â€¢ ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§: {result['summary']['total_characters']}")
    print(f"â€¢ ØªØ¹Ø¯Ø§Ø¯ ØµØ­Ù†Ù‡â€ŒÙ‡Ø§: {result['summary']['total_scenes']}")
    print(f"â€¢ Ø§Ù…ØªÛŒØ§Ø² consistency: {result['summary']['consistency_score']}")


if __name__ == "__main__":
    # Set up event loop for async execution
    asyncio.run(main())
